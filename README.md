## Null Hypothesis

A null hypothesis ($ ùêª_0 $) is a statement in hypothesis testing that assumes there is no effect, no difference, or no relationship between variables in a population. It represents the default or status quo assumption that researchers try to test against.

> `For example:`

> In a drug effectiveness test:

$ ùêª_0 $: The new drug has no effect on blood pressure.

> In an exam score comparison:

$ ùêª_0 $: The average test scores of two student groups are equal.

The null hypothesis is either rejected or not rejected based on statistical evidence. It is never "proven true," only retained if there isn't enough evidence against it.

## Alternative Hypothesis ($ H_a $ or $ H_1 $)

The alternative hypothesis ($ H_a $ or $ H_1 $)  is the statement that contradicts the null hypothesis and  represents what the researcher wants to prove. It suggests there is an effect, a difference, or a relationship between variables.

` Examples:`
> Drug effectiveness test:

$ H_0 $: The new drug has no effect on blood pressure.

$ H_a $: The new drug lowers blood pressure.

> `Exam score comparison:`

$ H_0 $: The average test scores of two student groups are equal.


$ H_a $: The average test scores of the two groups are different.

The alternative hypothesis is tested using statistical methods, and if strong evidence supports it, we reject the null hypothesis in favor of the alternative.


## Type I and Type II Errors in Hypothesis Testing
When performing hypothesis testing, two types of errors can occur:

### 1. Type I Error (False Positive)

Occurs when we reject the null hypothesis ($ H_0 $) even though it is actually true.

This means we detect an effect or difference that does not actually exist.

The probability of making a Type I error is denoted by $ ùõº $ (significance level).

#### üîπ Example:

A drug is actually ineffective, but the test concludes it works.
A court convicts an innocent person.


### 2. Type II Error (False Negative)

Occurs when we fail to reject the null hypothesis ($ H_0 $) even though it is actually false.

This means we miss detecting a real effect or difference.

The probability of making a Type II error is denoted by $ ùõΩ $.


üîπ Example:

A drug actually works, but the test concludes it does not.
A court lets a guilty person go free.
Key Trade-Off:
Reducing Type I errors (by lowering 
$ Œ± $) increases the risk of Type II errors, and vice versa.
Choosing the right balance depends on the situation‚Äîe.g., in medical trials, avoiding Type I errors is critical.